{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Jupyter notebooks in a nutshell\n",
    "* You are reading this line in a jupyter notebook.\n",
    "* A notebook consists of cells. A cell can contain either code or hypertext. \n",
    "    * This cell contains hypertext. The next cell contains code.\n",
    "* You can __run a cell__ with code by selecting it (click) and pressing `Ctrl + Enter` to execute the code and display output (if any).\n",
    "* Behind the curtains, there's a python interpreter that runs that code and remembers anything you defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Ctrl + S` to save changes (or use the button that looks like a floppy disk)\n",
    "* Top menu -> Kernel -> Interrupt (or Stop button) if you want it to stop running cell midway.\n",
    "* Top menu -> Kernel -> Restart (or cyclic arrow button) if interrupt doesn't fix the problem (you will lose all variables).\n",
    "* To find shortcuts: Top menu -> Help -> Keyboard Shortcuts\n",
    "\n",
    "\n",
    "* More: [Hacker's guide](http://arogozhnikov.github.io/2016/09/10/jupyter-features.html), [Beginner's guide'](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/), [Datacamp tutorial](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)\n",
    "\n",
    "Now __a very useful feature__ of jupyter notebooks: \n",
    "* if you're typing something, press `Tab` to see automatic suggestions, use arrow keys + enter to pick one.\n",
    "* if you move your cursor inside some function and press `Shift + Tab`, you'll get a help window. `Shift + (Tab , Tab)` will expand it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Decision trees & model selection\n",
    "\n",
    "![img](https://pbs.twimg.com/media/B13n2VVCIAA0hJS.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = np.load('/xdata/eparrish/mlhep2018/datasets/data.npz')\n",
    "X, y = toy_data['X'], toy_data['y']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save training time only 50% of the loaded data is used for training\n",
    "# train_test_split is our method of bootstrapping\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap='nipy_spectral');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees out of the box\n",
    "\n",
    "DecisionTreeClassifier has a number of parameters:\n",
    "* max_depth : a limit on tree depth (default : no limit)\n",
    "* min_samples_split : there should be at least this many samples to split further (default : 2)\n",
    "* min_samples_leaf : there should be at least this many samples on one side of a split to consider it valid (default : 1).\n",
    "* criterion : 'giny' or 'entropy' - split stuff over this parameter (default : giny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decision surface\n",
    "\n",
    "This function takes your classifier and plots it's prediction at each point. Let's see how it works.\n",
    "\n",
    "(this only works for two dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def plot_decision_surface(clf, X, y, plot_step = 0.2, cmap='nipy_spectral', figsize=(12,8)):\n",
    "    \"\"\"Plot the decision boundary of clf on X and y, visualize training points\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    x0_grid, x1_grid = np.meshgrid(np.arange(X[:, 0].min() - 1, X[:, 0].max() + 1, plot_step),\n",
    "                         np.arange(X[:, 1].min() - 1, X[:, 1].max() + 1, plot_step))\n",
    "    y_pred_grid = clf.predict(np.stack([x0_grid.ravel(), x1_grid.ravel()],axis=1)).reshape(x1_grid.shape)\n",
    "    plt.contourf(x0_grid, x1_grid, y_pred_grid, cmap=cmap, alpha=0.7)  \n",
    "    y_pred = clf.predict(X)    \n",
    "    plt.scatter(*X[y_pred==y].T,c = y[y_pred==y],\n",
    "                marker='.',cmap=cmap,alpha=0.5,label='correct')\n",
    "    plt.scatter(*X[y_pred!=y].T,c = y[y_pred!=y],\n",
    "                marker='x',cmap=cmap,s=50,label='errors')\n",
    "    plt.legend(loc='best')\n",
    "    print(\"Accuracy = \",accuracy_score(y, y_pred))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1, random_state=13, max_depth=3)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_surface(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Using  existing ensembles : Random Forest\n",
    "\n",
    "RandomForest combines bagging and random subspaces: each tree uses a fraction of training samples and while split in that tree is chosen among a subset of features. This leads to a slightly better performance.\n",
    "\n",
    "__Note:__ try re-running your code a few times and see what happens to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn spams numpy warnings\n",
    "# if you feel like digging into the scikit-learn/numpy internals, feel free to comment this out\n",
    "# https://stackoverflow.com/questions/49545947/sklearn-deprecationwarning-truth-value-of-an-array\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part V (final): machine learning with scikit-learn\n",
    "\n",
    "<img src='https://imgs.xkcd.com/comics/machine_learning.png' width=320px>\n",
    "\n",
    "Scikit-learn is _the_ tool for simple machine learning pipelines. \n",
    "\n",
    "It's a single library that unites a whole bunch of models under the common interface:\n",
    "* Create:__ `model = sklearn.whatever.ModelNameHere(parameters_if_any)`__\n",
    "* Train:__ `model.fit(X,y)`__\n",
    "* Predict:__ `model.predict(X_test)`__\n",
    "\n",
    "It also contains utilities for feature extraction, quality estimation or cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"/xdata/eparrish/mlhep2018/datasets/titanic.csv\", index_col='PassengerId') # this yields a pandas.DataFrame\"\n",
    "data['Age'] = data['Age'].fillna(value=data['Age'].mean())\n",
    "data['Fare'] = data['Fare'].fillna(value=data['Fare'].mean())\n",
    "sexToBool = {'male':0, 'female':1}\n",
    "data['Sex'] = data['Sex'].map(sexToBool)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the data\n",
    "Here's some of the columns\n",
    "* Survived - 1 if a person survived the shipwreck, 0 otherwise.\n",
    "* Pclass - passenger class. Pclass == 3 is cheap'n'cheerful, Pclass == 1 is for moneybags.\n",
    "* Name - a string with person's full name\n",
    "* Sex - a person's gender (in those good ol' times when there were just 2 of them)\n",
    "* Age - age in years, if available\n",
    "* SibSp - number of siblings on a ship\n",
    "* Parch - number of parents on a ship\n",
    "* Fare - ticket cost\n",
    "* Embarked - port where the passenger embarked\n",
    " * C = Cherbourg; Q = Queenstown; S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features = data[[\"Fare\",\"Age\"]].copy()\n",
    "answers = data[\"Survived\"]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(features[:-100], answers[:-100])\n",
    "\n",
    "test_predictions = model.predict(features[-100:])\n",
    "print(\"Test accuracy:\", accuracy_score(answers[-100:], test_predictions))\n",
    "\n",
    "\n",
    "print(\"Feature Importances: %s\" %(model.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final quest: add more features to achieve accuracy of at least 0.80\n",
    "\n",
    "__Hint:__ for string features like \"Sex\" or \"Embarked\" you will have to compute some kind of numeric representation.\n",
    "For example, 1 if male and 0 if female or vice versa \n",
    "\n",
    "__Hint II:__ you can use `model.feature_importances_` to get a hint on how much did it rely each of your features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sklearn [tutorials](http://scikit-learn.org/stable/tutorial/index.html)\n",
    "* Sklearn [examples](http://scikit-learn.org/stable/auto_examples/index.html)\n",
    "* SKlearn [cheat sheet](http://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
